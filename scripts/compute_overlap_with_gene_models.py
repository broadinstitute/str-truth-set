"""This script computes statistics about the overlap between the STR truth set vcf and other STR catalogs and
genomic regions of interest.
"""

import argparse
import collections
from intervaltree import Interval, IntervalTree
import gzip
import os
import pandas as pd
import re
import tqdm

GENE_MODELS = {
    "GencodeV42": "./ref/other/gencode.v42.annotation.gtf.gz",
    "MANEv1": "./ref/other/MANE.GRCh38.v1.0.ensembl_genomic.gtf.gz",
    "GencodeV43": "./ref/other/gencode.v43.annotation.gtf.gz",
    "MANEv1.2": "./ref/other/MANE.GRCh38.v1.2.ensembl_genomic.gtf.gz",
}


# approx. max size of a gene promoter region upstream of a gene
PROMOTER_SIZE = 1000  # bp


def parse_args():
    p = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    p.add_argument("--show-progress-bar", help="Show a progress bar in the terminal when processing variants.", action="store_true")
    p.add_argument("-n", help="Process only the 1st N rows of the truth set TSV. Useful for testing.", type=int)
    p.add_argument("gtf_path", help="Path of GTF file with gene annotations such as Gencode")
    p.add_argument("truth_set_tsv_or_bed_path", help="The STR variants TSV file generated by the STR truth set pipeline, "
                                                     "or an arbitrary bed file")
    p.add_argument("output_tsv", nargs="?", help="Optional output file path")

    args = p.parse_args()

    if not os.path.isfile(args.gtf_path):
        p.error(f"{args.gtf_path} not found")
    if not os.path.isfile(args.truth_set_tsv_or_bed_path):
        p.error(f"{args.truth_set_tsv_or_bed_path} not found")

    return args


def generate_gtf_records(gtf_path):
    """Parse the GTF file"""

    with gzip.open(gtf_path, "rt") as gtf_file:
        for i, line in enumerate(gtf_file):
            if line.startswith("#"):
                continue
            fields = line.strip().split("\t")
            feature_type = fields[2]
            if feature_type not in {
                "transcript",
                "exon",
                "CDS",
                "UTR",
                "promoter",
            }:
                continue

            annotation_source = fields[1]
            chrom = fields[0]
            start_1based = int(fields[3])
            end_1based = int(fields[4])

            meta_fields = {}
            for meta_field in fields[8].strip("; ").split(";"):
                key, value = meta_field.strip().replace('"', '').split()
                meta_fields[key] = value

            # don't emit the same exon or cds coords more than once
            strand = fields[6]

            gene_id = meta_fields["gene_id"].split(".")[0]
            transcript_id = meta_fields["transcript_id"].split(".")[0]

            record = {
                "feature_type": feature_type,
                "chrom": chrom,
                "start_1based": start_1based,
                "end_1based": end_1based,
                #"annotation_source": annotation_source,
                "strand": strand,
                "gene_id": gene_id,
                "transcript_id": transcript_id,
                "gene_name": meta_fields["gene_name"],
                "gene_type": meta_fields["transcript_type"],
                "transcript_type":  meta_fields["transcript_type"],
            }
            yield record

            # create a separate record for the transcript's promoter
            if feature_type == "transcript":
                if strand == "+":
                    promoter_start_1based = max(1, start_1based - PROMOTER_SIZE)
                    promoter_end_1based = start_1based - 1
                elif strand == "-":
                    promoter_start_1based = end_1based + 1
                    promoter_end_1based = end_1based + PROMOTER_SIZE
                else:
                    raise ValueError(f"Unexpected strand value in {gtf_path} line #{i}: {line}")

                promoter_record = dict(record)
                promoter_record.update({
                    "feature_type": "promoter",
                    "start_1based": promoter_start_1based,
                    "end_1based": promoter_end_1based,
                })

                yield promoter_record


def compute_genomic_region(input_row, interval_trees, transcript_id_to_cds_coords):
    """This method is called for each row in the truth set, and does overlap checks with the interval trees"""
    input_chrom = str(input_row["Chrom"]).replace("chr", "")
    input_locus_interval = Interval(input_row.Start1Based - 1, input_row.End1Based)

    # The truth set STR may overlap more than one region in the GTF. Return the most biologically important region.
    overlapping_intervals_from_gtf = interval_trees[input_chrom].overlap(input_locus_interval)
    overlapping_intervals_feature_types = {i.data["feature_type"]: i.data for i in overlapping_intervals_from_gtf}

    if "transcript" in overlapping_intervals_feature_types and "exon" not in overlapping_intervals_feature_types:
        overlapping_intervals_feature_types["intron"] = overlapping_intervals_feature_types["transcript"]

    for region in "CDS", "5' UTR", "3' UTR", "UTR", "exon", "intron", "promoter":  # handle both coding and non-coding transcripts
        if region not in overlapping_intervals_feature_types:
            continue
        record = overlapping_intervals_feature_types[region]
        if region == "UTR":
            region = compute_UTR_type(overlapping_intervals_feature_types["UTR"], transcript_id_to_cds_coords)
        return region, record["gene_name"], record["gene_id"], record["transcript_id"]

    return "intergenic", None, None, None


def compute_UTR_type(utr_record, transcript_id_to_cds_coords):

    if utr_record["feature_type"] != "UTR":
        raise utr_record["feature_type"]

    cds_coords = transcript_id_to_cds_coords.get(utr_record["transcript_id"])
    if cds_coords is None:
        print("WARNING: CDS not found for", utr_record["transcript_id"])
        print(utr_record)
        return "UTR"

    cds_chrom, cds_start_1based, cds_end_1based, cds_strand = cds_coords
    if utr_record["chrom"] != cds_chrom:
        print("ERROR:", utr_record["transcript_id"], "chrom in CDS utr_record != chrom in UTR utr_record:", cds_chrom, "vs", utr_record["chrom"])
        return "UTR"

    if utr_record["strand"] != cds_strand:
        print("ERROR:", utr_record["transcript_id"], "strand in CDS utr_record != strand in UTR utr_record:", cds_strand, "vs", utr_record["strand"])
        return "UTR"

    if (utr_record["strand"] == "+" and utr_record["end_1based"] < cds_start_1based) \
            or (utr_record["strand"] == "-" and utr_record["start_1based"] > cds_end_1based):
        return "5' UTR"
    elif (utr_record["strand"] == "-" and utr_record["end_1based"] < cds_start_1based) \
            or (utr_record["strand"] == "+" and utr_record["start_1based"] > cds_end_1based):
        return "3' UTR"
    else:
        print("ERROR: Something wrong with UTR info:", utr_record["strand"], utr_record["start_1based"],  utr_record["end_1based"],
              "or CDS info:", cds_coords)
        return "UTR"


def main():
    args = parse_args()

    gtf_prefix = re.sub(".gtf(.gz)?$", "", os.path.basename(args.gtf_path))
    gtf_label = "_".join(gtf_prefix.split(".")[0:2]).title()
    if not args.output_tsv:
        args.output_tsv = re.sub(".tsv(.gz)?", "", args.truth_set_tsv_or_bed_path)
        args.output_tsv = re.sub(".bed(.gz)?", "", args.output_tsv)
        args.output_tsv += f".with_{gtf_label.lower()}_columns"
        args.output_tsv += ".tsv.gz"

    # parse the GTF file into IntervalTrees
    iterator = generate_gtf_records(args.gtf_path)
    if args.show_progress_bar:
        iterator = tqdm.tqdm(iterator, unit=" GTF records")

    gtf_records = list(iterator)

    counters = collections.defaultdict(int)
    interval_trees = collections.defaultdict(IntervalTree)
    for record in gtf_records:
        chrom = record["chrom"].replace("chr", "")
        interval_trees[chrom].add(Interval(
            record["start_1based"] - 1,
            record["end_1based"],
            data=record,
        ))
        counters[record["feature_type"]] += 1
        counters[f"total"] += 1

    for key, count in sorted(counters.items(), key=lambda s: s[1], reverse=True):
        print(f"{count:10,d} {key}")

    # Iterate over all STR variants in the truth set and check overlap
    if args.truth_set_tsv_or_bed_path.endswith(".bed.gz") or args.truth_set_tsv_or_bed_path.endswith(".bed"):
        input_df = pd.read_table(args.truth_set_tsv_or_bed_path, names=["Chrom", "Start0Based", "End1Based"], index_col=False)
        input_df.loc[:, "Start1Based"] = input_df.Start0Based + 1
    else:
        input_df = pd.read_table(args.truth_set_tsv_or_bed_path)

    if args.n:
        input_df = input_df.iloc[0:args.n, :]

    # Cache all CDS coords to use later for converting "UTR" records into "5' UTR" and "3' UTR"
    transcript_id_to_cds_coords = {}
    gtf_records_iterator = gtf_records
    if args.show_progress_bar:
        gtf_records_iterator = tqdm.tqdm(gtf_records, "GTF records")
    for record in gtf_records_iterator:
        if record["feature_type"] == "CDS" and record["transcript_id"] not in transcript_id_to_cds_coords:
            transcript_id_to_cds_coords[record["transcript_id"]] = (
                record["chrom"],
                record["start_1based"],
                record["end_1based"],
                record["strand"],
            )

    # Compute genomic regions
    print(f"Processing rows from {args.truth_set_tsv_or_bed_path}")
    input_df[[f"GeneRegionFrom{gtf_label}", f"GeneNameFrom{gtf_label}", f"GeneIdFrom{gtf_label}", f"TranscriptIdFrom{gtf_label}"]] = input_df.apply(
        lambda input_row: compute_genomic_region(input_row, interval_trees, transcript_id_to_cds_coords), axis=1, result_type='expand')

    input_df.to_csv(args.output_tsv, sep="\t", index=False, header=True)
    print(f"Wrote {len(input_df):,d} rows to the output tsv: {args.output_tsv}")


if __name__ == "__main__":
    main()
